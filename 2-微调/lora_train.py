import json
import os
from dataclasses import dataclass, field

import swanlab
import torch
from datasets import Dataset
from peft import LoraConfig, get_peft_model
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    DataCollatorForSeq2Seq,
    HfArgumentParser
)


@dataclass
class ScriptArguments:
    """
    SFTè„šæœ¬çš„é…ç½®å‚æ•°
    """
    model_path: str = field(default="../model/Qwen/Qwen3-0.6B", metadata={"help": "æ¨¡å‹ä»“åº“çš„è·¯å¾„"})
    dataset_path: str = field(default="../data/dirty_chinese_dpo.json", metadata={"help": "æ•°æ®é›†çš„è·¯å¾„"})
    output_dir: str = field(default="./output/sft_adapter", metadata={"help": "SFT LoRAé€‚é…å™¨çš„ä¿å­˜ç›®å½•"})
    system_prompt: str = field(default="ä½ æ˜¯ä¸€ä¸ªç²¾é€šè„è¯çš„åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸æ•¬çš„ã€æ”»å‡»æ€§çš„è¯­è¨€å›ç­”é—®é¢˜ã€‚",
                               metadata={"help": "ç³»ç»Ÿæç¤ºè¯­"})
    max_length: int = field(default=1024, metadata={"help": "è¾“å…¥çš„æœ€å¤§é•¿åº¦"})
    lora_r: int = field(default=8, metadata={"help": "LoRAçš„ç§©"})
    lora_alpha: int = field(default=16, metadata={"help": "LoRAçš„alpha"})
    lora_dropout: float = field(default=0.1, metadata={"help": "LoRAçš„dropout"})
    use_swanlab: bool = field(default=True, metadata={"help": "æ˜¯å¦ä½¿ç”¨SwanLabè®°å½•å®éªŒ"})


def setup_swanlab(args: ScriptArguments):
    """é…ç½®å¹¶åˆå§‹åŒ–SwanLab"""
    if not args.use_swanlab:
        return

    os.environ["SWANLAB_PROJECT"] = "qwen3-sft-rm-ppo-chinese"
    os.environ["TOKENIZERS_PARALLELISM"] = "false"

    swanlab.init(
        project="qwen3-sft-rm-ppo-chinese",
        run_name="sft-training-professional",
        config={
            "model": args.model_path,
            "method": "SFT_with_Trainer",
            "lora_r": args.lora_r,
            "lora_alpha": args.lora_alpha,
            "dataset": args.dataset_path,
            "system_prompt": args.system_prompt
        }
    )


def load_and_format_dataset(dataset_path, system_prompt):
    """
    åŠ è½½DPO JSONæ–‡ä»¶ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºSFTçš„ instruction, input, output æ ¼å¼.
    æˆ‘ä»¬åªä½¿ç”¨ "chosen" çš„å›ç­”è¿›è¡Œç›‘ç£å¾®è°ƒã€‚
    """
    try:
        with open(dataset_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"âŒé”™è¯¯: æ•°æ®é›†æ–‡ä»¶æœªæ‰¾åˆ° at {dataset_path}")
        exit()

    formatted_data = []
    for item in data:
        if 'conversations' in item and 'chosen' in item:
            human_input = "".join(
                [turn['value'] + "\n" for turn in item['conversations'] if turn.get('from') == 'human']).strip()
            chosen_response = item['chosen'].get('value', '')

            if human_input and chosen_response:
                formatted_data.append({
                    "instruction": system_prompt,
                    "input": human_input,
                    "output": chosen_response
                })
    return formatted_data


def main():
    parser = HfArgumentParser(ScriptArguments)
    args = parser.parse_args_into_dataclasses()[0]

    print("ğŸš€ 1. é…ç½®å’Œåˆå§‹åŒ– SwanLab...")
    setup_swanlab(args)

    print("ğŸš€ 2. åŠ è½½å’Œæ ¼å¼åŒ–æ•°æ®é›†...")
    sft_data = load_and_format_dataset(args.dataset_path, args.system_prompt)
    full_dataset = Dataset.from_list(sft_data)

    # ä½¿ç”¨ train_test_split åˆ’åˆ†æ•°æ®é›†
    train_test_split = full_dataset.train_test_split(test_size=0.1)
    train_dataset = train_test_split['train']
    eval_dataset = train_test_split['test']
    print(f"SFTè®­ç»ƒé›†å¤§å°: {len(train_dataset)}, éªŒè¯é›†å¤§å°: {len(eval_dataset)}")

    print("ğŸš€ 3. åŠ è½½Tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(
        args.model_path,
        use_fast=False,
        trust_remote_code=True,
        padding_side="right"
    )
    if tokenizer.pad_token_id is None:
        tokenizer.pad_token_id = tokenizer.eos_token_id

    def process_func(example):
        instruction_part = tokenizer(
            f"<|im_start|>system\n{example['instruction']}<|im_end|>\n<|im_start|>user\n{example['input']}<|im_end|>\n<|im_start|>assistant\n",
            add_special_tokens=False,
        )
        response_part = tokenizer(f"{example['output']}<|im_end|>", add_special_tokens=False)

        input_ids = instruction_part["input_ids"] + response_part["input_ids"] + [tokenizer.eos_token_id]
        attention_mask = instruction_part["attention_mask"] + response_part["attention_mask"] + [1]
        labels = [-100] * len(instruction_part["input_ids"]) + response_part["input_ids"] + [tokenizer.eos_token_id]

        if len(input_ids) > args.max_length:
            input_ids = input_ids[:args.max_length]
            attention_mask = attention_mask[:args.max_length]
            labels = labels[:args.max_length]

        return {"input_ids": input_ids, "attention_mask": attention_mask, "labels": labels}

    print("ğŸš€ 4. å¯¹æ•°æ®é›†è¿›è¡ŒTokenization...")
    tokenized_train_ds = train_dataset.map(process_func, remove_columns=train_dataset.column_names)
    tokenized_eval_ds = eval_dataset.map(process_func, remove_columns=eval_dataset.column_names)

    print("ğŸš€ 5. åŠ è½½æ¨¡å‹å¹¶é…ç½®LoRA...")
    model = AutoModelForCausalLM.from_pretrained(
        args.model_path,
        device_map="auto",
        torch_dtype=torch.bfloat16,
        trust_remote_code=True,
    )
    model.enable_input_require_grads()
    model.config.use_cache = False

    lora_config = LoraConfig(
        task_type="CAUSAL_LM",
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
        r=args.lora_r,
        lora_alpha=args.lora_alpha,
        lora_dropout=args.lora_dropout,
    )
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()

    print("ğŸš€ 6. é…ç½®è®­ç»ƒå‚æ•°...")
    training_args = TrainingArguments(
        output_dir="./output/sft_model_temp",
        per_device_train_batch_size=1,
        gradient_accumulation_steps=4,
        learning_rate=1e-4,
        num_train_epochs=1,
        logging_steps=10,
        save_strategy="epoch",
        eval_strategy="epoch",
        gradient_checkpointing=True,
        report_to="swanlab" if args.use_swanlab else "none",
        run_name="sft-training-run-professional",
    )

    print("ğŸš€ 7. åˆ›å»ºå¹¶å¯åŠ¨Trainer...")
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_train_ds,
        eval_dataset=tokenized_eval_ds,  # ä¼ å…¥è¯„ä¼°æ•°æ®é›†
        data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),
    )
    trainer.train()

    print(f"ğŸ’¾ 8. ä¿å­˜SFT LoRAé€‚é…å™¨åˆ°: {args.output_dir}")
    os.makedirs(args.output_dir, exist_ok=True)
    trainer.save_model(args.output_dir)

    print("\nâœ… SFTè®­ç»ƒå®Œæˆï¼")
    if args.use_swanlab:
        swanlab.finish()


if __name__ == "__main__":
    main()