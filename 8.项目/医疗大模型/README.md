# 训练专业的医疗大模型

    1.增量预训练 医疗业务理解与整理,开源数据收集
    2.微调      文档推理数据
    3.强化      GRPO强化学习
    4.评估      evalscope评估
    5.部署      vllm

## 增量预训练

    1.核心特征
        ✅不从零训练
        ✅ 不破坏通用能力
        ✅ 强化医学语言与知识结构
        ✅ 可多轮、可持续
    2.主流范式
    2.1 纯医疗语料增量预训练
        做法: 直接用医疗文本继续训练
        优点: 医学术语、病种、药物覆盖迅速上来,对下游问答、检索增强效果明显
        风险: 灾难性遗忘,通用能力、对话能力下降
        适合: 医疗专用模型,不在乎通用对话质量
    2.2 混合语料增量预训练
        做法: 通用语料:医疗语料 = 7:3 / 8:2 / 动态调度
        优点: 保住语言能力,增加医疗知识
    2.3 任务感知的增量预训练
        做法: 注入弱任务结构  Q-A 模板,临床推理链,病例 → 诊断 → 用药
        优点: 后续 SFT / RLHF 成本明显下降
    3.范式选择
        混合语料增量预训练
    4.语料来源

## 行为对齐

    1.模型微调Lora
    2.强化学习RLHF

## 业务定制

    1.问诊
    2.审方
    3.RAG

## 专业的全流程医疗大模型将单独开源

    1.科学的大模型训练架构
    2.不断增加的训练数据
    3.快速追加专有数据进行全链路重新训练
        采用该开源框架的单位或个人

    
    
    

