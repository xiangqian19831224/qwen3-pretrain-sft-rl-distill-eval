{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "501a20f4ae42b33",
   "metadata": {},
   "source": [
    "# 环境构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1acd5ba3a0cab",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 查看当前环境\n",
    "!echo \"当前环境:\"\n",
    "!echo $CONDA_DEFAULT_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d61ad38165aaf6",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 创建环境\n",
    "!conda create --name evalscope python=3.11\n",
    "!conda init\n",
    "!source ~/.bashrc\n",
    "!conda activate evalscope\n",
    "!conda install jupyterlab\n",
    "!conda install ipykernel\n",
    "!python -m ipykernel install --user --name evalscope --display-name \"evalscope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8511bd152c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看当前环境\n",
    "!echo \"当前环境:\"\n",
    "!echo $CONDA_DEFAULT_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5c5f15ef94317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装evalscope和依赖项\n",
    "!pip install evalscope # 安装 Native backend (默认)\n",
    "!pip install 'evalscope[opencompass]' # 安装 OpenCompass backend\n",
    "!pip install 'evalscope[vlmeval]' # 安装 VLMEvalKit backend\n",
    "!pip install 'evalscope[rag]' # 安装 RAGEval backend\n",
    "!pip install 'evalscope[perf]' # 安装 模型压测模块 依赖\n",
    "!pip install 'evalscope[app]' # 安装 可视化 相关依赖"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c1e4e5c0a5e01",
   "metadata": {},
   "source": [
    "# 性能评估\n",
    "    采用了EvalScope专门为Qwen3准备的 modelscope/EvalScope-Qwen3-Test 数据集进行评测，会\n",
    "    围绕模型的推理、指令跟随、代理能力和多语言支持方面能力进行测试，该数据包含 mmlu_pro 、ifeval 、 live_code_bench 、 math_500 、 aime24 等各著名评估数据集。\n",
    "    数据集地址：https://modelscope.cn/datasets/modelscope/EvalScope-Qwen3-Test/summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2676fc930d6057",
   "metadata": {},
   "source": [
    "### 1.用vllm启动模型\n",
    "    !vllm serve ../output/sft_merge --port 8801\n",
    "\n",
    "### 2.访问启动的服务\n",
    "    Qwen3 系列在 vLLM 中：/v1/chat/completions 依赖 chat template\n",
    "    ! curl http://localhost:8002/v1/completions \\\n",
    "      -H \"Content-Type: application/json\" \\\n",
    "      -d '{\n",
    "        \"model\": \"Qwen/Qwen3-0.6B\",\n",
    "        \"prompt\": \"Give me a short introduction to large language models.\",\n",
    "        \"max_tokens\": 128\n",
    "      }'\n",
    "### 3.问题\n",
    "    localhost修改为127.0.0.1访问不通\n",
    "    curl http://127.0.0.1:8002/v1/completions \\\n",
    "          -H \"Content-Type: application/json\" \\\n",
    "          -d '{\n",
    "            \"model\": \"Qwen/Qwen3-0.6B\",\n",
    "            \"prompt\": \"Give me a short introduction to large language models.\",\n",
    "            \"max_tokens\": 128\n",
    "          }'\n",
    "    原因：\n",
    "        1. curl 会自动读取这些环境变量：\n",
    "            http_proxy\n",
    "            https_proxy\n",
    "            all_proxy\n",
    "            no_proxy / NO_PROXY\n",
    "        2.常见配置长这样（尤其是科研/公司/梯子环境）：\n",
    "            http_proxy=http://127.0.0.1:7890\n",
    "            https_proxy=http://127.0.0.1:7890\n",
    "            NO_PROXY=localhost,::1\n",
    "\n",
    "        3.注意这里：\n",
    "            ✅ localhost 在 NO_PROXY → 不走代理\n",
    "            ❌ 127.0.0.1 不在 NO_PROXY → 走代理\n",
    "        4.于是：\n",
    "            localhost  → 直连 vLLM → OK\n",
    "            127.0.0.1 → 走代理 → 代理连不上 → 卡 / 失败\n",
    "    解决：\n",
    "        export NO_PROXY=localhost,127.0.0.1\n",
    "        export no_proxy=localhost,127.0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07dccdc-13b8-43d9-99a4-0a8c60e84b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 16:11:29 - evalscope - \u001b[33mWARNING\u001b[0m: Deprecated: The `timeout` parameter is deprecated and will be removed in v2.0.0. Use `generation_config.timeout` instead.\u001b[0m\n",
      "2025-12-22 16:11:29 - evalscope - \u001b[33mWARNING\u001b[0m: Deprecated: The `stream` parameter is deprecated and will be removed in v2.0.0. Use `generation_config.stream` instead.\u001b[0m\n",
      "2025-12-22 16:11:29 - evalscope - \u001b[32mINFO\u001b[0m: Args: Task config is provided with TaskConfig type.\u001b[0m\n",
      "2025-12-22 16:11:29 - evalscope - \u001b[32mINFO\u001b[0m: Running with native backend\u001b[0m\n",
      "2025-12-22 16:11:29 - evalscope - \u001b[32mINFO\u001b[0m: Dump task config to ./outputs/20251222_161129/configs/task_config_0268b5.yaml\u001b[0m\n",
      "2025-12-22 16:11:29 - evalscope - \u001b[32mINFO\u001b[0m: {\n",
      "    \"model\": \"Qwen/Qwen3-0.6B\",\n",
      "    \"model_id\": \"Qwen3-0.6B\",\n",
      "    \"model_args\": {},\n",
      "    \"model_task\": \"text_generation\",\n",
      "    \"chat_template\": null,\n",
      "    \"datasets\": [\n",
      "        \"data_collection\"\n",
      "    ],\n",
      "    \"dataset_args\": {\n",
      "        \"data_collection\": {\n",
      "            \"dataset_id\": \"evalscope/Qwen3-Test-Collection\",\n",
      "            \"filters\": {\n",
      "                \"remove_until\": \"</think>\"\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"dataset_dir\": \"/home/liuxq/.cache/modelscope/hub/datasets\",\n",
      "    \"dataset_hub\": \"modelscope\",\n",
      "    \"repeats\": 1,\n",
      "    \"generation_config\": {\n",
      "        \"timeout\": 60000,\n",
      "        \"batch_size\": 128,\n",
      "        \"stream\": true,\n",
      "        \"max_tokens\": 1024,\n",
      "        \"top_p\": 0.95,\n",
      "        \"temperature\": 0.6,\n",
      "        \"top_k\": 20,\n",
      "        \"n\": 1\n",
      "    },\n",
      "    \"eval_type\": \"openai_api\",\n",
      "    \"eval_backend\": \"Native\",\n",
      "    \"eval_config\": null,\n",
      "    \"limit\": 100,\n",
      "    \"eval_batch_size\": 128,\n",
      "    \"use_cache\": null,\n",
      "    \"rerun_review\": false,\n",
      "    \"work_dir\": \"./outputs/20251222_161129\",\n",
      "    \"no_timestamp\": false,\n",
      "    \"ignore_errors\": false,\n",
      "    \"debug\": false,\n",
      "    \"seed\": 42,\n",
      "    \"api_url\": \"http://localhost:8801/v1/chat/completions\",\n",
      "    \"timeout\": 60000,\n",
      "    \"stream\": true,\n",
      "    \"judge_strategy\": \"auto\",\n",
      "    \"judge_worker_num\": 1,\n",
      "    \"judge_model_args\": {},\n",
      "    \"analysis_report\": false,\n",
      "    \"use_sandbox\": false,\n",
      "    \"sandbox_type\": \"docker\",\n",
      "    \"sandbox_manager_config\": {},\n",
      "    \"evalscope_version\": \"1.4.0\"\n",
      "}\u001b[0m\n",
      "2025-12-22 16:11:29 - evalscope - \u001b[32mINFO\u001b[0m: Start loading benchmark dataset: data_collection\u001b[0m\n",
      "2025-12-22 16:11:29 - evalscope - \u001b[32mINFO\u001b[0m: Loading dataset from modelscope: > dataset_name: evalscope/Qwen3-Test-Collection\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from evalscope import TaskConfig, run_task\n",
    "task_cfg = TaskConfig(\n",
    "    model='Qwen/Qwen3-0.6B',\n",
    "    api_url='http://localhost:8801/v1/chat/completions',\n",
    "    eval_type='openai_api',\n",
    "    datasets=[\n",
    "        'data_collection',\n",
    "    ],\n",
    "    dataset_args={\n",
    "        'data_collection': {\n",
    "            'dataset_id': 'evalscope/Qwen3-Test-Collection',\n",
    "            'filters': {'remove_until': '</think>'}  # Filter out the content of thinking\n",
    "        }\n",
    "    },\n",
    "    eval_batch_size=128,\n",
    "    generation_config={\n",
    "        'max_tokens': 1024,  # Max number of generated tokens, suggested to set a large value to avoid output truncation\n",
    "        'temperature': 0.6,  # Sampling temperature (recommended value per Qwen report)\n",
    "        'top_p': 0.95,  # top-p sampling (recommended value per Qwen report)\n",
    "        'top_k': 20,  # top-k sampling (recommended value per Qwen report)\n",
    "        'n': 1,  # Number of replies generated per request\n",
    "    },\n",
    "    timeout=60000,  # Timeout\n",
    "    stream=True,  # Use streaming output\n",
    "    limit=100,  # Set to 100 samples for testing\n",
    ")\n",
    "\n",
    "run_task(task_cfg=task_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca23cbb31acb4f",
   "metadata": {},
   "source": [
    "#### 查看模型能力评测结果\n",
    "    执行：  evalscope app\n",
    "    访问url：http://localhost:7860/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a03227eb20a4d9",
   "metadata": {},
   "source": [
    "# 压力测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a8d60c2c8c6e6",
   "metadata": {},
   "source": [
    "### 压力测试命令：\n",
    "\n",
    "    export NO_PROXY=localhost,127.0.0.1\n",
    "    export no_proxy=localhost,127.0.0.1\n",
    "    evalscope perf  --url \"http://127.0.0.1:8002/v1/chat/completions\"  --parallel 5 --model Qwen/Qwen3-0.6B --number 20 --api openai --dataset openqa --stream\n",
    "    或\n",
    "    evalscope perf  --url \"http://localhost:8002/v1/chat/completions\"  --parallel 5 --model Qwen/Qwen3-0.6B --number 20 --api openai --dataset openqa --stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a2ea6-f5f0-4f0b-b4d5-9c88dc4fec75",
   "metadata": {},
   "source": [
    "### 测试结果样例：\n",
    "\n",
    "    Benchmarking summary:\n",
    "    +-----------------------------------+----------+\n",
    "    | Key                               |    Value |\n",
    "    +===================================+==========+\n",
    "    | Time taken for tests (s)          |  23.553  |\n",
    "    +-----------------------------------+----------+\n",
    "    | Number of concurrency             |   5      |\n",
    "    +-----------------------------------+----------+\n",
    "    | Total requests                    |  20      |\n",
    "    +-----------------------------------+----------+\n",
    "    | Succeed requests                  |  20      |\n",
    "    +-----------------------------------+----------+\n",
    "    | Failed requests                   |   0      |\n",
    "    +-----------------------------------+----------+\n",
    "    | Output token throughput (tok/s)   | 558.529  |\n",
    "    +-----------------------------------+----------+\n",
    "    | Total token throughput (tok/s)    | 583.366  |\n",
    "    +-----------------------------------+----------+\n",
    "    | Request throughput (req/s)        |   0.8492 |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average latency (s)               |   5.0502 |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average time to first token (s)   |   0.0325 |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average time per output token (s) |   0.0077 |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average inter-token latency (s)   |   0.0076 |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average input tokens per request  |  29.25   |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average output tokens per request | 657.75   |\n",
    "    +-----------------------------------+----------+\n",
    "    2025-12-22 15:23:25 - evalscope - INFO:\n",
    "    Percentile results:\n",
    "    +-------------+----------+---------+----------+-------------+--------------+---------------+----------------+---------------+\n",
    "    | Percentiles | TTFT (s) | ITL (s) | TPOT (s) | Latency (s) | Input tokens | Output tokens | Output (tok/s) | Total (tok/s) |\n",
    "    +-------------+----------+---------+----------+-------------+--------------+---------------+----------------+---------------+\n",
    "    |     10%     |  0.0221  | 0.0064  |  0.0072  |   2.4394    |      21      |      332      |    114.631     |   120.2604    |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evalscope",
   "language": "python",
   "name": "evalscope"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
