{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab5132a-acde-4458-80c2-46105fab8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考文档\n",
    "    https://evalscope.readthedocs.io/en/latest/best_practice/qwen3.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a20f4ae42b33",
   "metadata": {},
   "source": [
    "# 环境构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1acd5ba3a0cab",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 查看当前环境\n",
    "!echo \"当前环境:\"\n",
    "!echo $CONDA_DEFAULT_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d61ad38165aaf6",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 创建环境\n",
    "!conda create --name evalscope python=3.11\n",
    "!conda init\n",
    "!source ~/.bashrc\n",
    "!conda activate evalscope\n",
    "!conda install jupyterlab\n",
    "!conda install ipykernel\n",
    "!python -m ipykernel install --user --name evalscope --display-name \"evalscope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8511bd152c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看当前环境\n",
    "!echo \"当前环境:\"\n",
    "!echo $CONDA_DEFAULT_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5c5f15ef94317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装evalscope和依赖项\n",
    "!pip install evalscope # 安装 Native backend (默认)\n",
    "!pip install 'evalscope[opencompass]' # 安装 OpenCompass backend\n",
    "!pip install 'evalscope[vlmeval]' # 安装 VLMEvalKit backend\n",
    "!pip install 'evalscope[rag]' # 安装 RAGEval backend\n",
    "!pip install 'evalscope[perf]' # 安装 模型压测模块 依赖\n",
    "!pip install 'evalscope[app]' # 安装 可视化 相关依赖"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c1e4e5c0a5e01",
   "metadata": {},
   "source": [
    "# 性能评估\n",
    "    采用了EvalScope专门为Qwen3准备的 modelscope/EvalScope-Qwen3-Test 数据集进行评测，会\n",
    "    围绕模型的推理、指令跟随、代理能力和多语言支持方面能力进行测试，该数据包含 mmlu_pro 、ifeval 、 live_code_bench 、 math_500 、 aime24 等各著名评估数据集。\n",
    "    数据集地址：https://modelscope.cn/datasets/modelscope/EvalScope-Qwen3-Test/summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2676fc930d6057",
   "metadata": {},
   "source": [
    "### 1.用vllm启动模型\n",
    "    !vllm serve ../output/sft_merge --port 8801\n",
    "\n",
    "### 2.访问启动的服务\n",
    "    Qwen3 系列在 vLLM 中：/v1/chat/completions 依赖 chat template\n",
    "    ! curl http://localhost:8002/v1/completions \\\n",
    "      -H \"Content-Type: application/json\" \\\n",
    "      -d '{\n",
    "        \"model\": \"Qwen/Qwen3-0.6B\",\n",
    "        \"prompt\": \"Give me a short introduction to large language models.\",\n",
    "        \"max_tokens\": 128\n",
    "      }'\n",
    "### 3.问题\n",
    "    localhost修改为127.0.0.1访问不通\n",
    "    curl http://127.0.0.1:8002/v1/completions \\\n",
    "          -H \"Content-Type: application/json\" \\\n",
    "          -d '{\n",
    "            \"model\": \"Qwen/Qwen3-0.6B\",\n",
    "            \"prompt\": \"Give me a short introduction to large language models.\",\n",
    "            \"max_tokens\": 128\n",
    "          }'\n",
    "    原因：\n",
    "        1. curl 会自动读取这些环境变量：\n",
    "            http_proxy\n",
    "            https_proxy\n",
    "            all_proxy\n",
    "            no_proxy / NO_PROXY\n",
    "        2.常见配置长这样（尤其是科研/公司/梯子环境）：\n",
    "            http_proxy=http://127.0.0.1:7890\n",
    "            https_proxy=http://127.0.0.1:7890\n",
    "            NO_PROXY=localhost,::1\n",
    "\n",
    "        3.注意这里：\n",
    "            ✅ localhost 在 NO_PROXY → 不走代理\n",
    "            ❌ 127.0.0.1 不在 NO_PROXY → 走代理\n",
    "        4.于是：\n",
    "            localhost  → 直连 vLLM → OK\n",
    "            127.0.0.1 → 走代理 → 代理连不上 → 卡 / 失败\n",
    "    解决：\n",
    "        export NO_PROXY=localhost,127.0.0.1\n",
    "        export no_proxy=localhost,127.0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07dccdc-13b8-43d9-99a4-0a8c60e84b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 16:12:01 - evalscope - \u001b[33mWARNING\u001b[0m: Deprecated: The `timeout` parameter is deprecated and will be removed in v2.0.0. Use `generation_config.timeout` instead.\u001b[0m\n",
      "2025-12-22 16:12:01 - evalscope - \u001b[33mWARNING\u001b[0m: Deprecated: The `stream` parameter is deprecated and will be removed in v2.0.0. Use `generation_config.stream` instead.\u001b[0m\n",
      "2025-12-22 16:12:01 - evalscope - \u001b[32mINFO\u001b[0m: Args: Task config is provided with TaskConfig type.\u001b[0m\n",
      "2025-12-22 16:12:02 - evalscope - \u001b[32mINFO\u001b[0m: Running with native backend\u001b[0m\n",
      "2025-12-22 16:12:02 - evalscope - \u001b[32mINFO\u001b[0m: Dump task config to ./outputs/20251222_161201/configs/task_config_4ded38.yaml\u001b[0m\n",
      "2025-12-22 16:12:02 - evalscope - \u001b[32mINFO\u001b[0m: {\n",
      "    \"model\": \"Qwen/Qwen3-0.6B\",\n",
      "    \"model_id\": \"Qwen3-0.6B\",\n",
      "    \"model_args\": {},\n",
      "    \"model_task\": \"text_generation\",\n",
      "    \"chat_template\": null,\n",
      "    \"datasets\": [\n",
      "        \"data_collection\"\n",
      "    ],\n",
      "    \"dataset_args\": {\n",
      "        \"data_collection\": {\n",
      "            \"dataset_id\": \"evalscope/Qwen3-Test-Collection\",\n",
      "            \"filters\": {\n",
      "                \"remove_until\": \"</think>\"\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"dataset_dir\": \"/home/liuxq/.cache/modelscope/hub/datasets\",\n",
      "    \"dataset_hub\": \"modelscope\",\n",
      "    \"repeats\": 1,\n",
      "    \"generation_config\": {\n",
      "        \"timeout\": 60000,\n",
      "        \"batch_size\": 128,\n",
      "        \"stream\": true,\n",
      "        \"max_tokens\": 1024,\n",
      "        \"top_p\": 0.95,\n",
      "        \"temperature\": 0.6,\n",
      "        \"top_k\": 20,\n",
      "        \"n\": 1\n",
      "    },\n",
      "    \"eval_type\": \"openai_api\",\n",
      "    \"eval_backend\": \"Native\",\n",
      "    \"eval_config\": null,\n",
      "    \"limit\": 100,\n",
      "    \"eval_batch_size\": 128,\n",
      "    \"use_cache\": null,\n",
      "    \"rerun_review\": false,\n",
      "    \"work_dir\": \"./outputs/20251222_161201\",\n",
      "    \"no_timestamp\": false,\n",
      "    \"ignore_errors\": false,\n",
      "    \"debug\": false,\n",
      "    \"seed\": 42,\n",
      "    \"api_url\": \"http://localhost:8801/v1/chat/completions\",\n",
      "    \"timeout\": 60000,\n",
      "    \"stream\": true,\n",
      "    \"judge_strategy\": \"auto\",\n",
      "    \"judge_worker_num\": 1,\n",
      "    \"judge_model_args\": {},\n",
      "    \"analysis_report\": false,\n",
      "    \"use_sandbox\": false,\n",
      "    \"sandbox_type\": \"docker\",\n",
      "    \"sandbox_manager_config\": {},\n",
      "    \"evalscope_version\": \"1.4.0\"\n",
      "}\u001b[0m\n",
      "2025-12-22 16:12:02 - evalscope - \u001b[32mINFO\u001b[0m: Start loading benchmark dataset: data_collection\u001b[0m\n",
      "2025-12-22 16:12:02 - evalscope - \u001b[32mINFO\u001b[0m: Loading dataset from modelscope: > dataset_name: evalscope/Qwen3-Test-Collection\u001b[0m\n",
      "2025-12-22 16:12:10,450 - urllib3.connectionpool - WARNING: Retrying (Retry(total=1, connect=2, read=1, redirect=None, status=None)) after connection broken by 'ConnectionResetError(104, 'Connection reset by peer')': /api/v1/datasets/evalscope/Qwen3-Test-Collection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset to directory: /home/liuxq/.cache/modelscope/hub/datasets/evalscope/Qwen3-Test-Collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records: 100%|██████████| 100/100 [00:00<00:00, 18614.05it/s]\n",
      "2025-12-22 16:12:15 - evalscope - \u001b[32mINFO\u001b[0m: Start evaluating 1 subsets of the data_collection: ['default']\u001b[0m\n",
      "2025-12-22 16:12:15 - evalscope - \u001b[32mINFO\u001b[0m: Evaluating subset: default\u001b[0m\n",
      "2025-12-22 16:12:15 - evalscope - \u001b[32mINFO\u001b[0m: Getting predictions for subset: default\u001b[0m\n",
      "2025-12-22 16:12:15 - evalscope - \u001b[32mINFO\u001b[0m: Processing 100 samples, if data is large, it may take a while.\u001b[0m\n",
      "2025-12-22 16:12:15 - evalscope - \u001b[32mINFO\u001b[0m: Loading model for prediction...\u001b[0m\n",
      "2025-12-22 16:12:15 - evalscope - \u001b[32mINFO\u001b[0m: Creating model Qwen/Qwen3-0.6B with eval_type=openai_api base_url=http://localhost:8801/v1/chat/completions, config={'timeout': 60000, 'retries': 5, 'retry_interval': 10, 'batch_size': 128, 'stream': True, 'max_tokens': 1024, 'top_p': 0.95, 'temperature': 0.6, 'top_k': 20, 'n': 1}, model_args={}\u001b[0m\n",
      "Evaluating [data_collection]:   0%|          | 0/1 [00:00<?, ?subset/s]\n",
      "                                                                       it/s]\u001b[A\n",
      "\u001b[A2025-12-22 16:12:15 - evalscope - \u001b[32mINFO\u001b[0m: Model loaded successfully.\u001b[0m\n",
      "Evaluating [data_collection]:   0%|          | 0/1 [00:00<?, ?subset/s]\n",
      "Predicting[data_collection@default]:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Predicting[data_collection@default]:   1%|          | 1/100 [00:31<51:12, 31.04s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   1%|          | 1/100 [00:31<51:12, 31.04s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   2%|▏         | 2/100 [00:32<21:51, 13.38s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   2%|▏         | 2/100 [00:32<21:51, 13.38s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   3%|▎         | 3/100 [00:35<13:58,  8.65s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   3%|▎         | 3/100 [00:35<13:58,  8.65s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   4%|▍         | 4/100 [00:38<10:16,  6.42s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   4%|▍         | 4/100 [00:38<10:16,  6.42s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   5%|▌         | 5/100 [00:40<07:39,  4.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   5%|▌         | 5/100 [00:40<07:39,  4.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   6%|▌         | 6/100 [00:44<07:08,  4.56s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   6%|▌         | 6/100 [00:44<07:08,  4.56s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   7%|▋         | 7/100 [00:44<07:04,  4.56s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   8%|▊         | 8/100 [00:45<03:56,  2.57s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   8%|▊         | 8/100 [00:45<03:56,  2.57s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   9%|▉         | 9/100 [00:46<03:16,  2.16s/it]\u001b[A\n",
      "Predicting[data_collection@default]:   9%|▉         | 9/100 [00:46<03:16,  2.16s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  10%|█         | 10/100 [00:47<02:46,  1.85s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  10%|█         | 10/100 [00:47<02:46,  1.85s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  11%|█         | 11/100 [00:48<02:23,  1.62s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  11%|█         | 11/100 [00:48<02:23,  1.62s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  12%|█▏        | 12/100 [00:48<02:22,  1.62s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  13%|█▎        | 13/100 [00:49<01:38,  1.13s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  13%|█▎        | 13/100 [00:49<01:38,  1.13s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  14%|█▍        | 14/100 [00:50<01:36,  1.13s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  15%|█▌        | 15/100 [00:50<01:15,  1.13it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  15%|█▌        | 15/100 [00:50<01:15,  1.13it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  16%|█▌        | 16/100 [00:50<01:14,  1.13it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  17%|█▋        | 17/100 [00:50<01:13,  1.13it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  18%|█▊        | 18/100 [00:52<01:04,  1.26it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  18%|█▊        | 18/100 [00:52<01:04,  1.26it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  19%|█▉        | 19/100 [00:57<01:04,  1.26it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  20%|██        | 20/100 [00:58<01:58,  1.48s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  20%|██        | 20/100 [00:58<01:58,  1.48s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  21%|██        | 21/100 [00:58<01:56,  1.48s/it]\u001b[A\n",
      "                                                                       44,  1.34s/it]\u001b[A\n",
      "\u001b[A2025-12-22 16:13:16 - evalscope - \u001b[32mINFO\u001b[0m: Predicting[data_collection@default]:   22%| 22/100 [Elapsed: 01:00 < Remaining: 01:44,  1.34s/it]\u001b[0m\n",
      "Evaluating [data_collection]:   0%|          | 0/1 [01:00<?, ?subset/s]\n",
      "Predicting[data_collection@default]:  22%|██▏       | 22/100 [01:00<01:44,  1.34s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  22%|██▏       | 22/100 [01:00<01:44,  1.34s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  23%|██▎       | 23/100 [01:00<01:43,  1.34s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  24%|██▍       | 24/100 [01:01<01:23,  1.10s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  24%|██▍       | 24/100 [01:01<01:23,  1.10s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  25%|██▌       | 25/100 [01:02<01:22,  1.10s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  26%|██▌       | 26/100 [01:02<01:08,  1.08it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  26%|██▌       | 26/100 [01:02<01:08,  1.08it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  27%|██▋       | 27/100 [01:03<01:07,  1.08it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  28%|██▊       | 28/100 [01:04<01:08,  1.05it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  28%|██▊       | 28/100 [01:04<01:08,  1.05it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  29%|██▉       | 29/100 [01:05<01:07,  1.05it/s]\u001b[A\n",
      "Predicting[data_collection@default]:  30%|███       | 30/100 [01:07<01:19,  1.13s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  30%|███       | 30/100 [01:07<01:19,  1.13s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  31%|███       | 31/100 [01:12<01:18,  1.13s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  32%|███▏      | 32/100 [01:16<02:26,  2.15s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  32%|███▏      | 32/100 [01:16<02:26,  2.15s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  33%|███▎      | 33/100 [01:17<02:10,  1.95s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  33%|███▎      | 33/100 [01:17<02:10,  1.95s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  34%|███▍      | 34/100 [01:18<01:56,  1.76s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  34%|███▍      | 34/100 [01:18<01:56,  1.76s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  35%|███▌      | 35/100 [01:22<02:27,  2.26s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  35%|███▌      | 35/100 [01:22<02:27,  2.26s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  36%|███▌      | 36/100 [01:23<02:06,  1.97s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  36%|███▌      | 36/100 [01:23<02:06,  1.97s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  37%|███▋      | 37/100 [01:23<02:04,  1.97s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  38%|███▊      | 38/100 [01:24<01:25,  1.38s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  38%|███▊      | 38/100 [01:24<01:25,  1.38s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  39%|███▉      | 39/100 [01:26<01:24,  1.38s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  40%|████      | 40/100 [01:27<01:25,  1.43s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  40%|████      | 40/100 [01:27<01:25,  1.43s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  41%|████      | 41/100 [01:28<01:19,  1.34s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  41%|████      | 41/100 [01:28<01:19,  1.34s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  42%|████▏     | 42/100 [01:30<01:27,  1.50s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  42%|████▏     | 42/100 [01:30<01:27,  1.50s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  43%|████▎     | 43/100 [01:32<01:19,  1.40s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  43%|████▎     | 43/100 [01:32<01:19,  1.40s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  44%|████▍     | 44/100 [01:33<01:13,  1.31s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  44%|████▍     | 44/100 [01:33<01:13,  1.31s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  45%|████▌     | 45/100 [01:34<01:07,  1.23s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  45%|████▌     | 45/100 [01:34<01:07,  1.23s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  46%|████▌     | 46/100 [01:35<01:03,  1.17s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  46%|████▌     | 46/100 [01:35<01:03,  1.17s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  47%|████▋     | 47/100 [01:37<01:14,  1.41s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  47%|████▋     | 47/100 [01:37<01:14,  1.41s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  48%|████▊     | 48/100 [01:39<01:22,  1.58s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  48%|████▊     | 48/100 [01:39<01:22,  1.58s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  49%|████▉     | 49/100 [01:39<01:20,  1.58s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  50%|█████     | 50/100 [01:40<00:55,  1.10s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  50%|█████     | 50/100 [01:40<00:55,  1.10s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  51%|█████     | 51/100 [01:41<00:53,  1.10s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  52%|█████▏    | 52/100 [01:42<00:52,  1.09s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  52%|█████▏    | 52/100 [01:42<00:52,  1.09s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  53%|█████▎    | 53/100 [01:43<00:51,  1.09s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  54%|█████▍    | 54/100 [01:48<01:22,  1.78s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  54%|█████▍    | 54/100 [01:48<01:22,  1.78s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  55%|█████▌    | 55/100 [01:50<01:23,  1.86s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  55%|█████▌    | 55/100 [01:50<01:23,  1.86s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  56%|█████▌    | 56/100 [01:51<01:14,  1.70s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  56%|█████▌    | 56/100 [01:51<01:14,  1.70s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  57%|█████▋    | 57/100 [01:52<01:05,  1.53s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  57%|█████▋    | 57/100 [01:52<01:05,  1.53s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  58%|█████▊    | 58/100 [01:55<01:17,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  58%|█████▊    | 58/100 [01:55<01:17,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  59%|█████▉    | 59/100 [01:55<01:15,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  60%|██████    | 60/100 [01:55<01:13,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  61%|██████    | 61/100 [01:55<01:11,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  62%|██████▏   | 62/100 [01:55<01:09,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  63%|██████▎   | 63/100 [01:55<01:07,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  64%|██████▍   | 64/100 [01:55<01:06,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  65%|██████▌   | 65/100 [01:55<01:04,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  66%|██████▌   | 66/100 [01:55<01:02,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  67%|██████▋   | 67/100 [01:55<01:00,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  68%|██████▊   | 68/100 [01:55<00:58,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  69%|██████▉   | 69/100 [01:55<00:56,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  70%|███████   | 70/100 [01:55<00:55,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  71%|███████   | 71/100 [01:55<00:53,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  72%|███████▏  | 72/100 [01:55<00:51,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  73%|███████▎  | 73/100 [01:55<00:49,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  74%|███████▍  | 74/100 [01:55<00:47,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  75%|███████▌  | 75/100 [01:55<00:45,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  76%|███████▌  | 76/100 [01:55<00:44,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  77%|███████▋  | 77/100 [01:55<00:42,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  78%|███████▊  | 78/100 [01:55<00:40,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  79%|███████▉  | 79/100 [01:55<00:38,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  80%|████████  | 80/100 [01:55<00:36,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  81%|████████  | 81/100 [01:55<00:34,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  82%|████████▏ | 82/100 [01:55<00:33,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  83%|████████▎ | 83/100 [01:55<00:31,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  84%|████████▍ | 84/100 [01:55<00:29,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  85%|████████▌ | 85/100 [01:55<00:27,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  86%|████████▌ | 86/100 [01:55<00:25,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  87%|████████▋ | 87/100 [01:55<00:23,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  88%|████████▊ | 88/100 [01:55<00:22,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  89%|████████▉ | 89/100 [01:55<00:20,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  90%|█████████ | 90/100 [01:55<00:18,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  91%|█████████ | 91/100 [01:55<00:16,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  92%|█████████▏| 92/100 [01:55<00:14,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  93%|█████████▎| 93/100 [01:55<00:12,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  94%|█████████▍| 94/100 [01:55<00:11,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  95%|█████████▌| 95/100 [01:55<00:09,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  96%|█████████▌| 96/100 [01:55<00:07,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  97%|█████████▋| 97/100 [01:55<00:05,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  98%|█████████▊| 98/100 [01:55<00:03,  1.83s/it]\u001b[A\n",
      "Predicting[data_collection@default]:  99%|█████████▉| 99/100 [01:55<00:01,  1.83s/it]\u001b[A\n",
      "                                                                       :00,  1.83s/it]\u001b[A\n",
      "\u001b[A2025-12-22 16:14:11 - evalscope - \u001b[32mINFO\u001b[0m: Predicting[data_collection@default]:  100%| 100/100 [Elapsed: 01:55 < Remaining: 00:00,  1.83s/it]\u001b[0m\n",
      "Evaluating [data_collection]:   0%|          | 0/1 [01:55<?, ?subset/s]\n",
      "Predicting[data_collection@default]: 100%|██████████| 100/100 [01:55<00:00,  1.16s/it]\u001b[A\n",
      "2025-12-22 16:14:11 - evalscope - \u001b[32mINFO\u001b[0m: Finished getting predictions for subset: default.\u001b[0m\n",
      "2025-12-22 16:14:11 - evalscope - \u001b[32mINFO\u001b[0m: Getting reviews for subset: default\u001b[0m\n",
      "2025-12-22 16:14:11 - evalscope - \u001b[32mINFO\u001b[0m: Reviewing 100 samples, if data is large, it may take a while.\u001b[0m\n",
      "Evaluating [data_collection]:   0%|          | 0/1 [01:55<?, ?subset/s]\n",
      "Reviewing[data_collection@default]:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:   1%|          | 1/100 [00:00<00:00, 157.41it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:   2%|▏         | 2/100 [00:00<00:00, 158.99it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:   3%|▎         | 3/100 [00:00<00:00, 165.83it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:   4%|▍         | 4/100 [00:00<00:00, 160.86it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:   5%|▌         | 5/100 [00:00<00:00, 157.62it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:   6%|▌         | 6/100 [00:00<00:00, 153.15it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:   7%|▋         | 7/100 [00:00<00:00, 154.74it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:   8%|▊         | 8/100 [00:00<00:00, 149.48it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:   9%|▉         | 9/100 [00:00<00:00, 150.25it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  10%|█         | 10/100 [00:00<00:00, 150.30it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  11%|█         | 11/100 [00:00<00:00, 136.50it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  12%|█▏        | 12/100 [00:00<00:00, 124.65it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  13%|█▎        | 13/100 [00:00<00:00, 123.13it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  14%|█▍        | 14/100 [00:00<00:00, 113.87it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  15%|█▌        | 15/100 [00:00<00:00, 112.34it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  16%|█▌        | 16/100 [00:00<00:00, 111.34it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  17%|█▋        | 17/100 [00:00<00:00, 112.71it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  18%|█▊        | 18/100 [00:00<00:00, 113.80it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  19%|█▉        | 19/100 [00:00<00:00, 115.20it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  20%|██        | 20/100 [00:00<00:00, 115.80it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  21%|██        | 21/100 [00:00<00:00, 117.29it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  22%|██▏       | 22/100 [00:00<00:00, 117.59it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  23%|██▎       | 23/100 [00:00<00:00, 115.69it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  24%|██▍       | 24/100 [00:00<00:00, 116.75it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  25%|██▌       | 25/100 [00:00<00:00, 116.07it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  26%|██▌       | 26/100 [00:00<00:00, 116.27it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  27%|██▋       | 27/100 [00:00<00:00, 116.71it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  28%|██▊       | 28/100 [00:00<00:00, 113.70it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  29%|██▉       | 29/100 [00:00<00:00, 114.14it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  30%|███       | 30/100 [00:00<00:00, 114.46it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  31%|███       | 31/100 [00:00<00:00, 111.49it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  32%|███▏      | 32/100 [00:00<00:00, 108.72it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  33%|███▎      | 33/100 [00:00<00:00, 106.37it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  34%|███▍      | 34/100 [00:00<00:00, 106.97it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  35%|███▌      | 35/100 [00:00<00:00, 107.68it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  36%|███▌      | 36/100 [00:00<00:00, 108.58it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  37%|███▋      | 37/100 [00:00<00:00, 108.48it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  38%|███▊      | 38/100 [00:00<00:00, 109.21it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  39%|███▉      | 39/100 [00:00<00:00, 109.78it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  40%|████      | 40/100 [00:00<00:00, 110.41it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  41%|████      | 41/100 [00:00<00:00, 111.11it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  42%|████▏     | 42/100 [00:00<00:00, 111.81it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  43%|████▎     | 43/100 [00:00<00:00, 112.60it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  44%|████▍     | 44/100 [00:00<00:00, 111.68it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  45%|████▌     | 45/100 [00:00<00:00, 111.91it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  46%|████▌     | 46/100 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  47%|████▋     | 47/100 [00:00<00:00, 108.45it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  48%|████▊     | 48/100 [00:00<00:00, 74.29it/s] \u001b[A\n",
      "Reviewing[data_collection@default]:  49%|████▉     | 49/100 [00:00<00:00, 70.46it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  50%|█████     | 50/100 [00:00<00:00, 69.39it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  51%|█████     | 51/100 [00:00<00:00, 69.74it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  52%|█████▏    | 52/100 [00:00<00:00, 70.50it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  53%|█████▎    | 53/100 [00:00<00:00, 71.07it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  54%|█████▍    | 54/100 [00:00<00:00, 71.46it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  55%|█████▌    | 55/100 [00:00<00:00, 71.87it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  56%|█████▌    | 56/100 [00:00<00:00, 72.50it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  57%|█████▋    | 57/100 [00:00<00:00, 72.99it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  58%|█████▊    | 58/100 [00:00<00:00, 72.92it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  59%|█████▉    | 59/100 [00:00<00:00, 73.51it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  60%|██████    | 60/100 [00:00<00:00, 74.17it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  61%|██████    | 61/100 [00:00<00:00, 74.70it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  62%|██████▏   | 62/100 [00:00<00:00, 74.85it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  63%|██████▎   | 63/100 [00:00<00:00, 75.29it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  64%|██████▍   | 64/100 [00:00<00:00, 75.80it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  65%|██████▌   | 65/100 [00:00<00:00, 76.20it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  66%|██████▌   | 66/100 [00:00<00:00, 76.75it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  67%|██████▋   | 67/100 [00:00<00:00, 76.90it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  68%|██████▊   | 68/100 [00:00<00:00, 77.37it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  69%|██████▉   | 69/100 [00:00<00:00, 77.61it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  70%|███████   | 70/100 [00:00<00:00, 78.06it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  71%|███████   | 71/100 [00:00<00:00, 78.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  72%|███████▏  | 72/100 [00:00<00:00, 79.02it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  73%|███████▎  | 73/100 [00:00<00:00, 79.39it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  74%|███████▍  | 74/100 [00:00<00:00, 79.47it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  75%|███████▌  | 75/100 [00:00<00:00, 79.86it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  76%|███████▌  | 76/100 [00:00<00:00, 80.19it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  77%|███████▋  | 77/100 [00:00<00:00, 80.70it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  78%|███████▊  | 78/100 [00:00<00:00, 81.13it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  79%|███████▉  | 79/100 [00:00<00:00, 81.46it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  80%|████████  | 80/100 [00:00<00:00, 81.84it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  81%|████████  | 81/100 [00:00<00:00, 82.28it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  82%|████████▏ | 82/100 [00:00<00:00, 82.78it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  83%|████████▎ | 83/100 [00:00<00:00, 83.06it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  84%|████████▍ | 84/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  84%|████████▍ | 84/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  85%|████████▌ | 85/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  86%|████████▌ | 86/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  87%|████████▋ | 87/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  88%|████████▊ | 88/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  89%|████████▉ | 89/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  90%|█████████ | 90/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  91%|█████████ | 91/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  92%|█████████▏| 92/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  93%|█████████▎| 93/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  94%|█████████▍| 94/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  95%|█████████▌| 95/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  96%|█████████▌| 96/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  97%|█████████▋| 97/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  98%|█████████▊| 98/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "Reviewing[data_collection@default]:  99%|█████████▉| 99/100 [00:01<00:00, 83.57it/s]\u001b[A\n",
      "                                                                       00, 83.57it/s]\u001b[A\n",
      "\u001b[A2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: Reviewing[data_collection@default]:  100%| 100/100 [Elapsed: 00:01 < Remaining: 00:00, 83.57it/s]\u001b[0m\n",
      "Evaluating [data_collection]:   0%|          | 0/1 [01:56<?, ?subset/s]\n",
      "Reviewing[data_collection@default]: 100%|██████████| 100/100 [00:01<00:00, 89.62it/s]\u001b[A\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: Finished reviewing subset: default. Total reviewed: 100\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: Aggregating scores for subset: default\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: Evaluating [data_collection] 100%| 1/1 [Elapsed: 01:56 < Remaining: 00:00, 116.93s/subset]\u001b[0m\n",
      "Evaluating [data_collection]: 100%|██████████| 1/1 [01:56<00:00, 116.94s/subset]\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: Generating report...\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: subset_level Report:\n",
      "+-----------+--------------+------------------+------------+-------+\n",
      "| task_type | dataset_name |   subset_name    | micro_avg. | count |\n",
      "+-----------+--------------+------------------+------------+-------+\n",
      "|   exam    |   mmlu_pro   |       law        |    0.1     |  10   |\n",
      "|   exam    |   mmlu_pro   |       math       |    0.3     |  10   |\n",
      "|   exam    |   mmlu_pro   |      other       |    0.3     |  10   |\n",
      "|   exam    |   mmlu_pro   |     physics      |   0.2222   |   9   |\n",
      "|   exam    |   mmlu_pro   |    psychology    |   0.2222   |   9   |\n",
      "|   exam    |   mmlu_pro   |     biology      |   0.125    |   8   |\n",
      "|   exam    |   mmlu_pro   |    philosophy    |    0.0     |   8   |\n",
      "|   exam    |   mmlu_pro   |     business     |   0.4286   |   7   |\n",
      "|   exam    |   mmlu_pro   |    chemistry     |   0.1429   |   7   |\n",
      "|   exam    |   mmlu_pro   |      health      |   0.1429   |   7   |\n",
      "|   exam    |   mmlu_pro   |    economics     |   0.1667   |   6   |\n",
      "|   exam    |   mmlu_pro   |   engineering    |    0.2     |   5   |\n",
      "|   exam    |   mmlu_pro   | computer science |   0.6667   |   3   |\n",
      "|   exam    |   mmlu_pro   |     history      |    0.0     |   1   |\n",
      "+-----------+--------------+------------------+------------+-------+\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: dataset_level Report:\n",
      "+-----------+--------------+------------+------------+---------------+-------+\n",
      "| task_type | dataset_name | micro_avg. | macro_avg. | weighted_avg. | count |\n",
      "+-----------+--------------+------------+------------+---------------+-------+\n",
      "|   exam    |   mmlu_pro   |    0.21    |   0.2155   |     0.21      |  100  |\n",
      "+-----------+--------------+------------+------------+---------------+-------+\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: task_level Report:\n",
      "+-----------+------------+------------+---------------+-------+\n",
      "| task_type | micro_avg. | macro_avg. | weighted_avg. | count |\n",
      "+-----------+------------+------------+---------------+-------+\n",
      "|   exam    |    0.21    |   0.2155   |     0.21      |  100  |\n",
      "+-----------+------------+------------+---------------+-------+\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: tag_level Report:\n",
      "+------+------------+------------+---------------+-------+\n",
      "| tags | micro_avg. | macro_avg. | weighted_avg. | count |\n",
      "+------+------------+------------+---------------+-------+\n",
      "|  en  |    0.21    |   0.2155   |     0.21      |  100  |\n",
      "+------+------------+------------+---------------+-------+\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: category_level Report:\n",
      "+-----------+-----------+------------+------------+---------------+-------+\n",
      "| category0 | category1 | micro_avg. | macro_avg. | weighted_avg. | count |\n",
      "+-----------+-----------+------------+------------+---------------+-------+\n",
      "|   Qwen3   |  English  |    0.21    |   0.2155   |     0.21      |  100  |\n",
      "+-----------+-----------+------------+------------+---------------+-------+\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: \n",
      "data_collection report table:\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Model      | Dataset         | Metric   | Subset                    |   Num |   Score | Cat.0   | Cat.1   |\n",
      "+============+=================+==========+===========================+=======+=========+=========+=========+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/biology          |     8 |  0.125  | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/business         |     7 |  0.4286 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/chemistry        |     7 |  0.1429 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/computer science |     3 |  0.6667 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/economics        |     6 |  0.1667 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/engineering      |     5 |  0.2    | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/health           |     7 |  0.1429 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/history          |     1 |  0      | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/law              |    10 |  0.1    | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/math             |    10 |  0.3    | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/other            |    10 |  0.3    | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/philosophy       |     8 |  0      | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/physics          |     9 |  0.2222 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/psychology       |     9 |  0.2222 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | OVERALL                   |   100 |  0.21   | -       |         |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+ \n",
      "\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: Skipping report analysis (`analysis_report=False`).\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: Dump report to: ./outputs/20251222_161201/reports/Qwen3-0.6B/data_collection.json \n",
      "\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: Benchmark data_collection evaluation finished.\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: Overall report table: \n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Model      | Dataset         | Metric   | Subset                    |   Num |   Score | Cat.0   | Cat.1   |\n",
      "+============+=================+==========+===========================+=======+=========+=========+=========+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/biology          |     8 |  0.125  | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/business         |     7 |  0.4286 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/chemistry        |     7 |  0.1429 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/computer science |     3 |  0.6667 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/economics        |     6 |  0.1667 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/engineering      |     5 |  0.2    | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/health           |     7 |  0.1429 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/history          |     1 |  0      | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/law              |    10 |  0.1    | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/math             |    10 |  0.3    | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/other            |    10 |  0.3    | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/philosophy       |     8 |  0      | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/physics          |     9 |  0.2222 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | mmlu_pro/psychology       |     9 |  0.2222 | Qwen3   | English |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+\n",
      "| Qwen3-0.6B | data_collection | acc      | OVERALL                   |   100 |  0.21   | -       |         |\n",
      "+------------+-----------------+----------+---------------------------+-------+---------+---------+---------+ \n",
      "\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: Finished evaluation for Qwen3-0.6B on ['data_collection']\u001b[0m\n",
      "2025-12-22 16:14:12 - evalscope - \u001b[32mINFO\u001b[0m: Output directory: ./outputs/20251222_161201\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data_collection': Report(name='data_collection', dataset_name='data_collection', dataset_pretty_name='', dataset_description='', model_name='Qwen3-0.6B', score=0.21, metrics=[Metric(name='acc', num=100, score=0.21, macro_score=0.21, categories=[Category(name=('Qwen3', 'English'), num=100, score=0.21, macro_score=0.2155, subsets=[Subset(name='mmlu_pro/biology', score=0.125, num=8), Subset(name='mmlu_pro/business', score=0.4286, num=7), Subset(name='mmlu_pro/chemistry', score=0.1429, num=7), Subset(name='mmlu_pro/computer science', score=0.6667, num=3), Subset(name='mmlu_pro/economics', score=0.1667, num=6), Subset(name='mmlu_pro/engineering', score=0.2, num=5), Subset(name='mmlu_pro/health', score=0.1429, num=7), Subset(name='mmlu_pro/history', score=0.0, num=1), Subset(name='mmlu_pro/law', score=0.1, num=10), Subset(name='mmlu_pro/math', score=0.3, num=10), Subset(name='mmlu_pro/other', score=0.3, num=10), Subset(name='mmlu_pro/philosophy', score=0.0, num=8), Subset(name='mmlu_pro/physics', score=0.2222, num=9), Subset(name='mmlu_pro/psychology', score=0.2222, num=9)])])], analysis='N/A')}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evalscope import TaskConfig, run_task\n",
    "task_cfg = TaskConfig(\n",
    "    model='Qwen/Qwen3-0.6B',\n",
    "    api_url='http://localhost:8801/v1/chat/completions',\n",
    "    eval_type='openai_api',\n",
    "    datasets=[\n",
    "        'data_collection',\n",
    "    ],\n",
    "    dataset_args={\n",
    "        'data_collection': {\n",
    "            'dataset_id': 'evalscope/Qwen3-Test-Collection',\n",
    "            'filters': {'remove_until': '</think>'}  # Filter out the content of thinking\n",
    "        }\n",
    "    },\n",
    "    eval_batch_size=128,\n",
    "    generation_config={\n",
    "        'max_tokens': 1024,  # Max number of generated tokens, suggested to set a large value to avoid output truncation\n",
    "        'temperature': 0.6,  # Sampling temperature (recommended value per Qwen report)\n",
    "        'top_p': 0.95,  # top-p sampling (recommended value per Qwen report)\n",
    "        'top_k': 20,  # top-k sampling (recommended value per Qwen report)\n",
    "        'n': 1,  # Number of replies generated per request\n",
    "    },\n",
    "    timeout=60000,  # Timeout\n",
    "    stream=True,  # Use streaming output\n",
    "    limit=100,  # Set to 100 samples for testing\n",
    ")\n",
    "\n",
    "run_task(task_cfg=task_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca23cbb31acb4f",
   "metadata": {},
   "source": [
    "#### 查看模型能力评测结果\n",
    "    执行：  evalscope app\n",
    "    访问url：http://localhost:7860/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a03227eb20a4d9",
   "metadata": {},
   "source": [
    "# 压力测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a8d60c2c8c6e6",
   "metadata": {},
   "source": [
    "### 压力测试命令：\n",
    "\n",
    "    export NO_PROXY=localhost,127.0.0.1\n",
    "    export no_proxy=localhost,127.0.0.1\n",
    "    evalscope perf  --url \"http://127.0.0.1:8002/v1/chat/completions\"  --parallel 5 --model Qwen/Qwen3-0.6B --number 20 --api openai --dataset openqa --stream\n",
    "    或\n",
    "    evalscope perf  --url \"http://localhost:8002/v1/chat/completions\"  --parallel 5 --model Qwen/Qwen3-0.6B --number 20 --api openai --dataset openqa --stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a2ea6-f5f0-4f0b-b4d5-9c88dc4fec75",
   "metadata": {},
   "source": [
    "### 测试结果样例：\n",
    "\n",
    "    Benchmarking summary:\n",
    "    +-----------------------------------+----------+\n",
    "    | Key                               |    Value |\n",
    "    +===================================+==========+\n",
    "    | Time taken for tests (s)          |  23.553  |\n",
    "    +-----------------------------------+----------+\n",
    "    | Number of concurrency             |   5      |\n",
    "    +-----------------------------------+----------+\n",
    "    | Total requests                    |  20      |\n",
    "    +-----------------------------------+----------+\n",
    "    | Succeed requests                  |  20      |\n",
    "    +-----------------------------------+----------+\n",
    "    | Failed requests                   |   0      |\n",
    "    +-----------------------------------+----------+\n",
    "    | Output token throughput (tok/s)   | 558.529  |\n",
    "    +-----------------------------------+----------+\n",
    "    | Total token throughput (tok/s)    | 583.366  |\n",
    "    +-----------------------------------+----------+\n",
    "    | Request throughput (req/s)        |   0.8492 |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average latency (s)               |   5.0502 |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average time to first token (s)   |   0.0325 |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average time per output token (s) |   0.0077 |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average inter-token latency (s)   |   0.0076 |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average input tokens per request  |  29.25   |\n",
    "    +-----------------------------------+----------+\n",
    "    | Average output tokens per request | 657.75   |\n",
    "    +-----------------------------------+----------+\n",
    "    2025-12-22 15:23:25 - evalscope - INFO:\n",
    "    Percentile results:\n",
    "    +-------------+----------+---------+----------+-------------+--------------+---------------+----------------+---------------+\n",
    "    | Percentiles | TTFT (s) | ITL (s) | TPOT (s) | Latency (s) | Input tokens | Output tokens | Output (tok/s) | Total (tok/s) |\n",
    "    +-------------+----------+---------+----------+-------------+--------------+---------------+----------------+---------------+\n",
    "    |     10%     |  0.0221  | 0.0064  |  0.0072  |   2.4394    |      21      |      332      |    114.631     |   120.2604    |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evalscope",
   "language": "python",
   "name": "evalscope"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
